{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "939fc1d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cdriver'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rankdata\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partial\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnetwork\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmaco\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MaCo\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(batch_size, trainset_size, testset_size, validset_size, data_fn):\n\u001b[1;32m     30\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_fn\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cdriver'"
     ]
    }
   ],
   "source": [
    "\"\"\"Generates the example results on the logistic map example\n",
    "\"\"\"\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.nn import Module, Sequential, Linear, ReLU, MSELoss, PReLU\n",
    "from torch import Tensor\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn.functional import relu\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy.signal import correlate, correlation_lags\n",
    "from scipy.stats import rankdata\n",
    "from functools import partial\n",
    "\n",
    "from cdriver.network.maco import MaCo\n",
    "\n",
    "\n",
    "def load_data(batch_size, trainset_size, testset_size, validset_size, data_fn):\n",
    "    data = pd.read_csv('data_fn', index_col=0).values\n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5), (0.3)),\n",
    "                                    torch.Tensor.float,\n",
    "                                    partial(torch.squeeze, axis=0)])\n",
    "\n",
    "    x = transform(data[:, 1:2])\n",
    "    y = transform(data[:, 2:3])\n",
    "    z = scale(data[:-1, 0])  # we only use it in the final evaluation of the learned represenation\n",
    "    #\n",
    "    Q = torch.cat((x[:-1], y[:-1], y[1:]), axis=-1)\n",
    "    Targ = x[1:]\n",
    "\n",
    "    # Split into Traing test and validation sets\n",
    "    splitted_data = split_sets([Q, Targ, z],\n",
    "                               trainset_size,\n",
    "                               testset_size,\n",
    "                               validset_size)\n",
    "    (Q_train, Targ_train, z_train), (Q_test, Targ_test, z_test), (Q_valid, Targ_valid, z_valid) \\\n",
    "        = splitted_data\n",
    "\n",
    "    train_loader = make_batches(Q_train, Targ_train, batch_size=batch_size)\n",
    "    test_loader = Q_test, Targ_test\n",
    "    valid_loader = Q_valid, Targ_valid\n",
    "    return train_loader, test_loader, valid_loader, z_valid\n",
    "\n",
    "def make_batches(Q, target, batch_size):\n",
    "    maxsize = Q.shape[0]\n",
    "    i = np.arange(maxsize)\n",
    "    np.random.shuffle(i)\n",
    "    return list(zip(Q[i, :].split(batch_size), target[i, :].split(batch_size)))\n",
    "\n",
    "def split_sets(data, trainset_size, testset_size, validset_size):\n",
    "    def split_one(X, trainset_size, testset_size, validset_size):\n",
    "        N = X.shape[0]\n",
    "        X_train = X[:int(trainset_size * N)]\n",
    "        X_test = X[int(trainset_size * N):int((trainset_size + testset_size) * N)]\n",
    "        X_valid = X[int((trainset_size + testset_size) * N):]\n",
    "\n",
    "        return X_train, X_test, X_valid\n",
    "\n",
    "    # normalize sizes\n",
    "    S = trainset_size + testset_size + validset_size\n",
    "    trainset_part, testset_part, validset_part = (i / S for i in [trainset_size, testset_size, validset_size])\n",
    "\n",
    "    splitteds = [split_one(i, trainset_part, testset_part, validset_part) for i in data]\n",
    "\n",
    "    return list(zip(*splitteds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c5155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Parameters\n",
    "    dx = 1\n",
    "    dy = 2\n",
    "    dz = 1\n",
    "    nh = 20 # number of hidden units\n",
    "    mapper_kwargs = dict(n_h1=nh, n_h2=nh)\n",
    "    coach_kwargs = dict(n_h1=nh)\n",
    "    device= torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    n_models = 2  # number of models to train\n",
    "\n",
    "    trainset_size = 80\n",
    "    testset_size = 10\n",
    "    validset_size = 10\n",
    "\n",
    "    n_epochs = 4000\n",
    "    batch_size = 2000\n",
    "    data_fn = '../../data/logistic_1d_data.csv'\n",
    "\n",
    "    # Load in data & preprocessing to pytorch\n",
    "    train_loader, test_loader, valid_loader, z_valid = load_data(batch_size, trainset_size,\n",
    "                                                                 testset_size, validset_size,\n",
    "                                                                 data_fn)\n",
    "\n",
    "    models = [MaCo(Ex=dx, Ey=dy, Ez=dz,\n",
    "                   mh_kwargs=mapper_kwargs, ch_kwargs=coach_kwargs, device=device) for i in range(n_models)]\n",
    "\n",
    "    # Train models\n",
    "    train_losses = []\n",
    "    test_loss = []\n",
    "    for i in tqdm(range(n_models)):\n",
    "        train_losses += [models[i].train_loop(train_loader, n_epochs, lr=1e-2)]\n",
    "        test_loss += [models[i].test_loop(test_loader)]\n",
    "    train_losses = np.array(train_losses).T\n",
    "\n",
    "    # Pick the best model on the test set\n",
    "    ind_best_model = np.argmin(test_loss)\n",
    "    best_model = models[ind_best_model]\n",
    "\n",
    "    # compute reconstruction on the validation set\n",
    "    valid_loss, x_pred, z_pred, hz_pred = best_model.valid_loop(valid_loader)\n",
    "\n",
    "    # Compute correlation for all models on validation set\n",
    "    r_reconst = []\n",
    "    r_predict = []\n",
    "    for model in tqdm(models):\n",
    "        preds = model.valid_loop(valid_loader)\n",
    "        r_predict += [np.corrcoef(preds[1], valid_loader[1][:, 0])[0, 1] ]\n",
    "        r_reconst += [np.corrcoef(preds[2], z_valid)[0, 1]]\n",
    "\n",
    "    # Save out results\n",
    "    res_dict = {'cc_pred': z_pred,\n",
    "                'cc_valid': z_valid,\n",
    "                'x_valid': valid_loader[1].squeeze().detach().numpy(),\n",
    "                'x_past_valid': valid_loader[0][:, 0],\n",
    "                'x_pred': x_pred,\n",
    "                'Y_1_valid': valid_loader[0][:, 1],\n",
    "                'Y_2_valid': valid_loader[0][:, 2],\n",
    "                }\n",
    "\n",
    "    df = pd.DataFrame(res_dict)\n",
    "\n",
    "    # # Save out the Results (uncomment to rewrite the current results)\n",
    "    # df.to_csv('./resdata/mappercoach_res.csv')\n",
    "    # np.save('./resdata/learning_curves.npy', train_losses)\n",
    "    # np.save('./resdata/test_loss.npy', test_loss)\n",
    "    # torch.save(best_model, './resdata/best_model.pth')\n",
    "    # with open('./resdata/models.pkl', 'wb') as f:\n",
    "    #     pickle.dump(models, f)\n",
    "    # pd.DataFrame({'r_predict':r_predict, 'r_reconst':r_reconst}).to_csv('./resdata/r_values.csv')\n",
    "    # print(np.corrcoef(z_valid, z_pred))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2594fd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb5a4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c42aea0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cdriver'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcdriver\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cdriver'"
     ]
    }
   ],
   "source": [
    "import cdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb094bae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
